{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 1805.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/saranpannasuriyaporn/Desktop/Code workspace/Speech_to_tabular/models/model2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from huggingface_hub import snapshot_download\n",
    "#snapshot_download(repo_id=\"wannaphong/wav2vec2-large-xlsr-53-th-cv8-newmm\",local_dir=\"models/model1\")\n",
    "#snapshot_download(repo_id=\"airesearch/wav2vec2-large-xlsr-53-th\",local_dir=\"models/model2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"wannaphong/wav2vec2-large-xlsr-53-th-cv8-newmm\", local_files_only=True) # แปลงให้เป็น embedding (ใช้ convolution)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"wannaphong/wav2vec2-large-xlsr-53-th-cv8-newmm\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/model2\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(PATH,local_files_only=True) # แปลงให้เป็น embedding (ใช้ convolution)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(PATH,local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"processor_class\": \"Wav2Vec2ProcessorWithLM\",\n",
       "  \"return_attention_mask\": false,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: Wav2Vec2CTCTokenizer(name_or_path='models/model2', vocab_size=70, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]', 'additional_special_tokens': [AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True)]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process_utils import speech_file_to_array_fn\n",
    "\n",
    "speech, _, _ = speech_file_to_array_fn('samples/sample.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['สวัสดี คระ ชื่อ อะไร คัด รบกวน เหนียว ช่วย บ่อ ด้วย น้า']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Test Processor\n",
    "inputs = processor(speech, sampling_rate=16000,return_tensors=\"pt\")\n",
    "\n",
    "# Test Model\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs.input_values,).logits #185 features\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "prediction = processor.batch_decode(predicted_ids)\n",
    "\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_to_tabular_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
